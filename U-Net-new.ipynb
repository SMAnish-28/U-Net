{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c50cb0-fc33-4d5d-83f8-fb9892022c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\maham\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\maham\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "   ---------------------------------------- 0.0/11.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.2 MB 1.0 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.8/11.2 MB 985.5 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/11.2 MB 1.1 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.0/11.2 MB 1.1 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.6/11.2 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.6/11.2 MB 1.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.8/11.2 MB 1.1 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.2 MB 1.1 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.6/11.2 MB 1.2 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 2.9/11.2 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.4/11.2 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.7/11.2 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.9/11.2 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/11.2 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/11.2 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/11.2 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/11.2 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/11.2 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/11.2 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.5/11.2 MB 986.9 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.5/11.2 MB 986.9 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.5/11.2 MB 986.9 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.5/11.2 MB 986.9 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.0/11.2 MB 920.7 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.2/11.2 MB 940.3 kB/s eta 0:00:07\n",
      "   ------------------- -------------------- 5.5/11.2 MB 953.2 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.8/11.2 MB 965.3 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.8/11.2 MB 965.3 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.0/11.2 MB 943.9 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.0/11.2 MB 943.9 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.0/11.2 MB 943.9 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.0/11.2 MB 943.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.3/11.2 MB 865.2 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.3/11.2 MB 865.2 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 6.6/11.2 MB 856.7 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 6.8/11.2 MB 863.0 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.1/11.2 MB 875.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.3/11.2 MB 895.1 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 7.6/11.2 MB 894.8 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.9/11.2 MB 904.3 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.1/11.2 MB 911.8 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 8.4/11.2 MB 923.8 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.2 MB 937.0 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.2 MB 937.0 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.9/11.2 MB 922.7 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 9.2/11.2 MB 930.6 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.4/11.2 MB 930.5 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.7/11.2 MB 939.3 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.0/11.2 MB 952.0 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.5/11.2 MB 975.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.2 MB 986.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.2 MB 989.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.2/11.2 MB 987.4 kB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a7994a-6c21-4437-81c4-3dd3e4409119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 1156s 12s/step - loss: 1.6095 - accuracy: 0.2001 - val_loss: 1.6094 - val_accuracy: 0.2001\n",
      "Epoch 2/50\n",
      " 52/100 [==============>...............] - ETA: 7:27 - loss: 1.6094 - accuracy: 0.1999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the U-Net model\n",
    "def unet_model(input_shape=(128, 128, 12), num_classes=5):\n",
    "    \"\"\"\n",
    "    U-Net model for land terrain classification.\n",
    "\n",
    "    Args:\n",
    "        input_shape: Shape of the input image (height, width, channels).\n",
    "        num_classes: Number of terrain classes for classification.\n",
    "\n",
    "    Returns:\n",
    "        Compiled U-Net model.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder: Contracting path\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Decoder: Expanding path\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = layers.Conv2D(num_classes, (1, 1), activation='softmax')(c9)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Data preparation\n",
    "# def load_data(image_folder, image_size=(128, 128)):\n",
    "#     \"\"\"\n",
    "#     Load and preprocess images from a folder.\n",
    "\n",
    "#     Args:\n",
    "#         image_folder: Path to the folder containing images.\n",
    "#         image_size: Target size for resizing images.\n",
    "\n",
    "#     Returns:\n",
    "#         Numpy array of images.\n",
    "#     \"\"\"\n",
    "#     images = []\n",
    "#     labels = []  # Placeholder if you have labels\n",
    "#     for image_name in os.listdir(image_folder):\n",
    "#         img_path = os.path.join(image_folder, image_name)\n",
    "#         img = imread(img_path)\n",
    "#         img = resize(img, image_size, mode='constant', preserve_range=True)\n",
    "#         images.append(img)\n",
    "#     return np.array(images)\n",
    "\n",
    "def load_data(image_folder, image_size=(128, 128), num_channels=12):\n",
    "    images = []\n",
    "    for image_name in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, image_name)\n",
    "        img = imread(img_path)\n",
    "        img = resize(img, image_size + (num_channels,), mode='constant', preserve_range=True)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "\n",
    "# Main setup\n",
    "input_shape = (128, 128, 12)  # Adjust according to your Sentinel-2 data\n",
    "num_classes = 5\n",
    "\n",
    "train_folder = 'C://Users/maham/OneDrive/Desktop/forest_train/'  # Update with your actual path\n",
    "test_folder = 'C://Users/maham/OneDrive/Desktop/forest_test/'  # Update with your actual path\n",
    "\n",
    "# Load and preprocess data\n",
    "X_train = load_data(train_folder, image_size=input_shape[:2])\n",
    "X_test = load_data(test_folder, image_size=input_shape[:2])\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Generate dummy labels (Replace with actual labels if available)\n",
    "Y_train = np.random.randint(0, num_classes, (len(X_train), input_shape[0], input_shape[1]))\n",
    "Y_test = np.random.randint(0, num_classes, (len(X_test), input_shape[0], input_shape[1]))\n",
    "\n",
    "# One-hot encoding labels\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and compile the model\n",
    "model = unet_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model and collect accuracy/loss data\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# Plot training and validation accuracy and loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
