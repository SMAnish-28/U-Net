{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cdf82e-7b6d-4009-9e97-31c816615c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\maham\\anaconda3\\envs\\tensorflow\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\maham\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\maham\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\maham\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\maham\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b859ce07-0d76-4be6-9213-e94f93717fa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv9' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 109\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43munet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mLEARNING_RATE), \n\u001b[0;32m    111\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m    112\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 102\u001b[0m, in \u001b[0;36munet_model\u001b[1;34m(input_size)\u001b[0m\n\u001b[0;32m     98\u001b[0m c9 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(c9)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# outputs = Conv2D(len(categories), (1, 1), activation='softmax')(c9)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Update the final layer\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;28mlen\u001b[39m(categories), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\u001b[43mconv9\u001b[49m)  \n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# num_classes = len(categories)\u001b[39;00m\n\u001b[0;32m    105\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39m[inputs], outputs\u001b[38;5;241m=\u001b[39m[outputs])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'conv9' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define paths\n",
    "data_dir = 'C:/Users/maham/OneDrive/Desktop/DataSet/'  # Replace with your dataset folder path\n",
    "categories = os.listdir(data_dir)\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "IMG_CHANNELS = 3\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Helper function to load images and labels\n",
    "def load_data(data_dir, categories):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, category in enumerate(categories):\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        for img_file in os.listdir(category_path):\n",
    "            img_path = os.path.join(category_path, img_file)\n",
    "            img = tf.keras.utils.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "            img_array = tf.keras.utils.img_to_array(img) / 255.0\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load the dataset\n",
    "images, labels = load_data(data_dir, categories)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Build the U-Net model\n",
    "def unet_model(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Contracting Path\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Expanding Path\n",
    "    u6 = UpSampling2D((2, 2))(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = UpSampling2D((2, 2))(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = UpSampling2D((2, 2))(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = UpSampling2D((2, 2))(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    # outputs = Conv2D(len(categories), (1, 1), activation='softmax')(c9)\n",
    "    # Update the final layer\n",
    "    outputs = Conv2D(len(categories), (1, 1), activation=\"softmax\")(c9)  \n",
    "    # num_classes = len(categories)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = unet_model()\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
